1. 기억의 3층 구조 (Layered Memory)
데이터를 무조건 다 저장하는 대신, 효율적으로 압축하여 관리합니다.
L1: 최근 대화 (Raw Buffer): 직전 5~10개의 대화 원문. 현재 대화의 뉘앙스와 흐름 파악용.
L2: 압축된 요약 (Rolling Summary): SLM이 기존 요약과 새 대화를 합쳐 단 하나의 String으로 계속 업데이트. (메인 LLM의 컨텍스트 절약)
L3: 장기 기억 (Vector DB): 요약에서 누락되거나 아주 오래된 정보 중 중요한 사실들을 벡터화하여 저장 (LanceDB, ChromaDB 등 활용).

2. SLM(Small Language Model)의 역할 (The Gatekeeper)
메인 LLM(GPT-4 등)을 호출하기 전, 가벼운 모델(예: Llama 3 8B, Phi-3)이 전처리를 담당합니다.
요약: 대화가 쌓이면 "지금까지의 내용을 한 문장으로 합쳐줘"라고 수행.
검색 쿼리 생성: 유저의 질문을 보고 "장기 기억에서 무엇을 찾아야 할지" 키워드 추출.
필터링: 굳이 기억이 필요 없는 단순 인사 등은 DB 조회를 건너뛰게 함.

3. 데이터 흐름 (Workflow)
입력: 유저가 채팅을 침.
분석 (SLM): 현재 질문에 과거 기억이 필요한지 판단 + 검색 키워드 추출.
조회: Vector DB에서 관련 정보(L3)를 가져오고, 변수에 저장된 요약본(L2)과 최근 대화(L1)를 불러옴.
조립: [L3: 장기 기억] + [L2: 요약] + [L1: 최근 대화] + 질문 형태로 프롬프트 구성.
답변: 메인 LLM이 최종 답변 생성.
업데이트: 대화 종료 후 SLM이 L2(요약)를 갱신하고 필요시 L3(DB)에 저장.